

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/head.png">
  <link rel="icon" href="/img/head.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Zhili Yang">
  <meta name="keywords" content="">
  
    <meta name="description" content="Overview This post From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning One sentence summary: Let the model choose the data for itself ##### Design">
<meta property="og:type" content="article">
<meta property="og:title" content="Implementation">
<meta property="og:url" content="http://example.com/2024/10/21/Implementation/index.html">
<meta property="og:site_name" content="Zhili Yang&#39;s Blog">
<meta property="og:description" content="Overview This post From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning One sentence summary: Let the model choose the data for itself ##### Design">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/impl.png">
<meta property="article:published_time" content="2024-10-21T12:03:13.000Z">
<meta property="article:modified_time" content="2024-10-22T08:21:58.803Z">
<meta property="article:author" content="Zhili Yang">
<meta property="article:tag" content="PAPER">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/impl.png">
  
  
  
  <title>Implementation - Zhili Yang&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":55,"cursorChar":">_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"V00BmRbjy0xa9r1TkJZRqVX4-MdYXbMMI","app_key":"Oht7XhOFVBgTl4ILm6USAWE9","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Zhili Yang&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/impl.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Implementation"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-10-21 20:03" pubdate>
          October 21, 2024 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.7k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          15 mins
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> views
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Implementation</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="overview">Overview</h1>
<p>This post</p>
<h3
id="from-quantity-to-quality-boosting-llm-performance-with-self-guided-data-selection-for-instruction-tuning">From
Quantity to Quality: Boosting LLM Performance with Self-Guided Data
Selection for Instruction Tuning</h3>
<p>One sentence summary: Let the model choose the data for itself #####
Design experiment 1. Use k-means to filter out 1k instructions to
fine-tune the data for training and train only one epoch 2. This
cherry-model is then used to filter the data in reverse, using the IFD
metric 3. <span class="math display">\[IFD_\theta(Q,
A)=\frac{s_\theta(A|Q)}{s_\theta(A)}\]</span></p>
<img src="/2024/10/21/Implementation/1.png" srcset="/img/loading.gif" lazyload class="">
<ol start="4" type="1">
<li>This formula selects data with IFD less than 1 and a high ratio,
which means that these data are difficult for the model to learn</li>
<li>Then use this part to filter out more valuable training data to
train the model</li>
</ol>
<h5 id="reproduce-process">Reproduce process</h5>
<p>Use configuration: <img src="/2024/10/21/Implementation/2.png" srcset="/img/loading.gif" lazyload class=""> 1. Select 1k pieces of data
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs script">python cherry_seletion/data_analysis.py \<br>    --data_path data/code.json \<br>    --save_path code_data_pre.pt \<br>    --model_name_or_path &quot;meta-llama/Llama-3.1-8B&quot; \<br>    --max_length 512 \<br>    --prompt code \<br>    --mod pre<br></code></pre></td></tr></table></figure></p>
<p>--data_path: The targeted dataset in the Alpaca format</p>
<p>--save_path: The path to save the .pt file containing embeddings or
scores</p>
<p>--prompt: The prompt type used for training and selecting data, can
choose between alpaca or wiz</p>
<p>Change in <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">        <span class="hljs-keyword">elif</span> args.prompt == <span class="hljs-string">&#x27;code&#x27;</span>:<br>            input_i = data_i[<span class="hljs-string">&#x27;prompt&#x27;</span>] <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;prompt&#x27;</span> <span class="hljs-keyword">in</span> data_i.keys() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;&#x27;</span><br>            <span class="hljs-keyword">if</span> input_i == <span class="hljs-string">&#x27;&#x27;</span>:<br>                temp_dict = &#123;<span class="hljs-string">&#x27;instruction&#x27;</span>:instruct_i&#125;<br>                promt_to_use = PROMPT_DICT[<span class="hljs-string">&quot;prompt_no_input&quot;</span>].format_map(temp_dict)<br>                whole_text = promt_to_use + output_i<br>                instruct_i = promt_to_use<br>            <span class="hljs-keyword">else</span>:<br>                temp_dict = &#123;<span class="hljs-string">&#x27;instruction&#x27;</span>:instruct_i,<span class="hljs-string">&#x27;prompt&#x27;</span>:input_i&#125;<br>                promt_to_use = PROMPT_DICT[<span class="hljs-string">&quot;prompt_input&quot;</span>].format_map(temp_dict)<br>                whole_text = promt_to_use + output_i<br>                instruct_i = promt_to_use<br>                <br>           <br><span class="hljs-keyword">and</span> some other replacement of <span class="hljs-built_in">input</span>-prompt, output-response<br></code></pre></td></tr></table></figure></p>
<p>--mod: pre used for getting needed embeddings or scores on selecting
pre-experienced samples and cherry used for cherry</p>
<img src="/2024/10/21/Implementation/3.png" srcset="/img/loading.gif" lazyload class="">
<p>Some parameters are on the meta device because they were offloaded to
the cpu. Reason: Probably because of insufficient GPU memory</p>
<p>It was estimated to be about 25min, but it was actually very, very
long... But The author also admitted it in limitation. the main
limitation of this method is the inconvenience of training the
pre-experienced model.</p>
<p>So I randomly selected 1k pieces of data to feel ~ Time Used:
27.98344091176987 (min)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs script">python cherry_seletion/data_by_cluster.py \<br>    --pt_data_path code_data_pre.pt \<br>    --json_data_path data/code.json \<br>    --json_save_path code_data_pre.json \<br>    --sample_num 8 \<br>    --kmeans_num_clusters 100 \<br>    --low_th 25 \<br>    --up_th 75<br></code></pre></td></tr></table></figure>
<p>--pt_data_path: The .pt file from previous step containing needed
embeddings or scores</p>
<p>--json_data_path: The targeted dataset in the Alpaca format</p>
<p>--json_save_path: The path to save the selected pre-experienced
samples</p>
<p>--sample_num: How many samples will be selected in each cluster</p>
<p>--kmeans_num_clusters: How many clusters will be generated by
K-Means</p>
<p>--low_th and --up_th: The lower and Upper threshold for selecting
samples within each cluster</p>
<p>In an instant, 420 items were selected (why 420 items? Is it because
each cluster is not selected?)</p>
<ol start="2" type="1">
<li>Train Pre-Experienced Model <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs script">!pip install unsloth<br></code></pre></td></tr></table></figure></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> unsloth <span class="hljs-keyword">import</span> FastLanguageModel<br><span class="hljs-keyword">import</span> torch<br>max_seq_length = <span class="hljs-number">2048</span> <span class="hljs-comment"># Choose any! We auto support RoPE Scaling internally!</span><br>dtype = <span class="hljs-literal">None</span> <span class="hljs-comment"># None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+</span><br>load_in_4bit = <span class="hljs-literal">True</span> <span class="hljs-comment"># Use 4bit quantization to reduce memory usage. Can be False.</span><br><br><br>model, tokenizer = FastLanguageModel.from_pretrained(<br>    model_name = <span class="hljs-string">&quot;unsloth/Meta-Llama-3.1-8B&quot;</span>,<br>    max_seq_length = max_seq_length,<br>    dtype = dtype,<br>    load_in_4bit = load_in_4bit,<br>    <span class="hljs-comment"># token = &quot;hf_...&quot;, # use one if using gated models like meta-llama/Llama-2-7b-hf</span><br>)<br><br><br>model = FastLanguageModel.get_peft_model(<br>    model,<br>    r = <span class="hljs-number">16</span>, <span class="hljs-comment"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span><br>    target_modules = [<span class="hljs-string">&quot;q_proj&quot;</span>, <span class="hljs-string">&quot;k_proj&quot;</span>, <span class="hljs-string">&quot;v_proj&quot;</span>, <span class="hljs-string">&quot;o_proj&quot;</span>,<br>                      <span class="hljs-string">&quot;gate_proj&quot;</span>, <span class="hljs-string">&quot;up_proj&quot;</span>, <span class="hljs-string">&quot;down_proj&quot;</span>,],<br>    lora_alpha = <span class="hljs-number">16</span>,<br>    lora_dropout = <span class="hljs-number">0</span>, <span class="hljs-comment"># Supports any, but = 0 is optimized</span><br>    bias = <span class="hljs-string">&quot;none&quot;</span>,    <span class="hljs-comment"># Supports any, but = &quot;none&quot; is optimized</span><br>    <span class="hljs-comment"># [NEW] &quot;unsloth&quot; uses 30% less VRAM, fits 2x larger batch sizes!</span><br>    use_gradient_checkpointing = <span class="hljs-string">&quot;unsloth&quot;</span>, <span class="hljs-comment"># True or &quot;unsloth&quot; for very long context</span><br>    random_state = <span class="hljs-number">3407</span>,<br>    use_rslora = <span class="hljs-literal">False</span>,  <span class="hljs-comment"># We support rank stabilized LoRA</span><br>    loftq_config = <span class="hljs-literal">None</span>, <span class="hljs-comment"># And LoftQ</span><br>)<br><br><br>alpaca_prompt = <span class="hljs-string">&quot;&quot;&quot;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span><br><span class="hljs-string"></span><br><span class="hljs-string">### Instruction:</span><br><span class="hljs-string">&#123;&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">### Input:</span><br><span class="hljs-string">&#123;&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">### Response:</span><br><span class="hljs-string">&#123;&#125;&quot;&quot;&quot;</span><br><br>EOS_TOKEN = tokenizer.eos_token <span class="hljs-comment"># Must add EOS_TOKEN</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">formatting_prompts_func</span>(<span class="hljs-params">examples</span>):<br>    instructions = examples[<span class="hljs-string">&quot;instruction&quot;</span>]<br>    inputs       = examples[<span class="hljs-string">&quot;prompt&quot;</span>]<br>    outputs      = examples[<span class="hljs-string">&quot;response&quot;</span>]<br>    texts = []<br>    <span class="hljs-keyword">for</span> instruction, <span class="hljs-built_in">input</span>, output <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(instructions, inputs, outputs):<br>        <span class="hljs-comment"># Must add EOS_TOKEN, otherwise your generation will go on forever!</span><br>        text = alpaca_prompt.<span class="hljs-built_in">format</span>(instruction, <span class="hljs-built_in">input</span>, output) + EOS_TOKEN<br>        texts.append(text)<br>    <span class="hljs-keyword">return</span> &#123; <span class="hljs-string">&quot;text&quot;</span> : texts, &#125;<br><span class="hljs-keyword">pass</span><br><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;code_data_pre.json&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br>dataset = dataset.<span class="hljs-built_in">map</span>(formatting_prompts_func, batched = <span class="hljs-literal">True</span>,)<br><br><br><br><span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> SFTTrainer<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments<br><span class="hljs-keyword">from</span> unsloth <span class="hljs-keyword">import</span> is_bfloat16_supported<br><br>trainer = SFTTrainer(<br>    model = model,<br>    tokenizer = tokenizer,<br>    train_dataset = dataset,<br>    dataset_text_field = <span class="hljs-string">&quot;text&quot;</span>,<br>    max_seq_length = max_seq_length,<br>    dataset_num_proc = <span class="hljs-number">2</span>,<br>    packing = <span class="hljs-literal">False</span>, <span class="hljs-comment"># Can make training 5x faster for short sequences.</span><br>    args = TrainingArguments(<br>        per_device_train_batch_size = <span class="hljs-number">2</span>,<br>        gradient_accumulation_steps = <span class="hljs-number">4</span>,<br>        warmup_steps = <span class="hljs-number">5</span>,<br>        num_train_epochs = <span class="hljs-number">1</span>, <span class="hljs-comment"># Set this for 1 full training run.</span><br>        <span class="hljs-comment">#max_steps = 60,</span><br>        learning_rate = <span class="hljs-number">2e-4</span>,<br>        fp16 = <span class="hljs-keyword">not</span> is_bfloat16_supported(),<br>        bf16 = is_bfloat16_supported(),<br>        logging_steps = <span class="hljs-number">1</span>,<br>        optim = <span class="hljs-string">&quot;adamw_8bit&quot;</span>,<br>        weight_decay = <span class="hljs-number">0.01</span>,<br>        lr_scheduler_type = <span class="hljs-string">&quot;linear&quot;</span>,<br>        seed = <span class="hljs-number">3407</span>,<br>        output_dir = <span class="hljs-string">&quot;outputs&quot;</span>,<br>    ),<br>)<br><br>trainer.train()<br></code></pre></td></tr></table></figure>
<p>Time Used: 8:03min</p>
<ol start="3" type="1">
<li>通过IFD选cherry data <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs script">python cherry_seletion/data_analysis.py \<br>    --data_path data/code.json \<br>    --save_path code_data_cherry.pt \<br>    --model_name_or_path &quot;outputs/checkpoint-52&quot; \<br>    --max_length 512 \<br>    --prompt code \<br>    --mod cherry<br></code></pre></td></tr></table></figure> Time Used: 6.185897000630697
(min)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs script">python cherry_seletion/data_by_IFD.py \<br>    --pt_data_path code_data_cherry.pt \<br>    --json_data_path data/code.json \<br>    --json_save_path code_data_cherry.json \<br>    --model_name_or_path &quot;outputs/checkpoint-52&quot; \<br>    --max_length 2048 \<br>    --sample_rate 0.06 \<br>    --prompt code<br></code></pre></td></tr></table></figure>
<p>--sample_rate: How many cherry samples you would like to select? You
can also use --sample_number to set the exact number of samples.
Finally, 60 pieces of data with IFD&lt;1 were obtained, and soted sorted
them from smallest to largest</p>
<p>Smallest ifd: <figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">instruction:<span class="hljs-comment">&quot;Create a Python function `create_element` to create an XML-like element. It takes one required argument &#x27;name&#x27; (a string) and two optional arguments &#x27;attributes&#x27; (a dictionary of name-value pairs) and &#x27;children&#x27; (a list of elements created by this function). The function should return an object that has a &#x27;name&#x27; attribute and &#x27;attributes&#x27; and &#x27;children&#x27; properties. Here is an example: ```python elem = create_element(&#x27;root&#x27;, children=[create_element(&#x27;child1&#x27;, attributes=&#123;&#x27;name&#x27;: &#x27;foo&#x27;&#125;), create_element(&#x27;child2&#x27;, attributes=&#123;&#x27;name&#x27;: &#x27;bar&#x27;&#125;)]) elem.children[0].attributes[&#x27;name&#x27;] == &#x27;foo&#x27; ``` Your code should pass the following test case: ```python elem = create_element(&#x27;root&#x27;, children=[create_element(&#x27;child1&#x27;, attributes=&#123;&#x27;name&#x27;: &#x27;foo&#x27;&#125;), create_element(&#x27;child2&#x27;, attributes=&#123;&#x27;name&#x27;: &#x27;bar&#x27;&#125;)]) assert elem.children[0].attributes[&#x27;name&#x27;] == &#x27;foo&#x27; ```&quot;</span><br>prompt:<span class="hljs-comment">&quot;Provide the best response to a given instruction. Follow the following steps to craft your response: 1. reason about the given instruction 2. provide a high-quality solution 3. offer a concise explanation 4. write tests to verify the correctness your solution ## Example 1 ### Instruction Construct a Python function `create_folds(data, count)` to create a list of folds from the given data, where each fold is a subsequence of the original data. The length of each fold should be approximately equal with at most a difference of 1. The function should satisfy the following assertion: ```python assert create_folds(range(12), 2) == [range(0, 6), range(6, 12)] assert create_folds(range(8), 2) == [range(0, 4), range(4, 8)] assert create_folds(range(25), -5) == [] assert create_folds(range(6), 2) == [range(0, 3), range(3, 6)] ``` ### Response [Reasoning] To create a Python function that generates a list of folds from given data with each fold having approximately equal length (with at most a difference of 1 between any two folds), you can follow these steps: 1. Return an empty list immediately if `count` is non-positive since it&#x27;s not possible to create a valid number of folds. 2. Divide the total length of the data by `count`, rounding down, to get the minimum number of items each fold should have. 3. Calculate the remainder to see how many extra items need to be distributed among the folds. They are distributed one by one to the first `remainder` folds. 4. Use a loop to create each fold, adjusting the starting and ending indices based on the calculations above to ensure each fold has the correct number of items. [Implementation] Here&#x27;s how you can implement this: ```python def create_folds(data, count): # Return an empty list if count is non-positive if count &lt;= 0: return [] data_length = len(data) fold_size = data_length // count remainder = data_length % count folds = [] start_index = 0 for i in range(count): # Add 1 element to each of the first `remainder` folds end_index = start_index + fold_size + (1 if i &lt; remainder else 0) folds.append(range(start_index, end_index)) start_index = end_index return folds ``` [Explanation] This implementation ensures that each fold has an equal length with at most a difference of 1 between any two folds. It handles edge cases, such as a non-positive `count`, by returning an empty list as specified. [Tests] You can test your code with the provided assertions to verify that the function works correctly: ```python assert create_folds(range(12), 2) == [range(0, 6), range(6, 12)] assert create_folds(range(8), 2) == [range(0, 4), range(4, 8)] assert create_folds(range(25), -5) == [] assert create_folds(range(6), 2) == [range(0, 3), range(3, 6)] ``` ## Example 2 ### Instruction Create a Python function `create_element` to create an XML-like element. It takes one required argument &#x27;name&#x27; (a string) and two optional arguments &#x27;attributes&#x27; (a dictionary of name-value pairs) and &#x27;children&#x27; (a list of elements created by this function). The function should return an object that has a &#x27;name&#x27; attribute and &#x27;attributes&#x27; and &#x27;children&#x27; properties. Here is an example: ```python elem = create_element(&#x27;root&#x27;, children=[create_element(&#x27;child1&#x27;, attributes=&#123;&#x27;name&#x27;: &#x27;foo&#x27;&#125;), create_element(&#x27;child2&#x27;, attributes=&#123;&#x27;name&#x27;: &#x27;bar&#x27;&#125;)]) elem.children[0].attributes[&#x27;name&#x27;] == &#x27;foo&#x27; ``` ### Response&quot;</span><br>response:<span class="hljs-comment">&quot;To create a Python function that creates an XML-like element with a given name, attributes, and children, you can follow these steps: 1. Define a `create_element` function that takes a required &#x27;name&#x27; argument and two optional arguments &#x27;attributes&#x27; and &#x27;children&#x27;. 2. Declare a class `Element` that holds the name, attributes, and children of the element. 3. Inside the `create_element` function, create a new `Element` object with the given &#x27;name&#x27;, &#x27;attributes&#x27;, and &#x27;children&#x27;. 4. Return the newly created `Element` object. 5. Test your function with the given assertions. Here&#x27;s how you can implement this: ```python class Element: def __init__(self, name, attributes=None, children=None): self.name = name self.attributes = attributes or &#123;&#125; self.children = children or [] def create_element(name, attributes=None, children=None): return Element(name, attributes, children) ```&quot;</span><br></code></pre></td></tr></table></figure></p>
<p>bigest ifd: <figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">instruction:<span class="hljs-comment">&quot;Write a Python function that takes a dictionary as an argument and makes a copy of it by creating a new dictionary. Modify the copy by deleting a specific key from the dictionary if it exists. Your code should pass the following test case: ```python dictionary = &#123;&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3&#125; new_dict = copy_and_delete(dictionary, &#x27;a&#x27;) assert new_dict == &#123;&#x27;b&#x27;: 2, &#x27;c&#x27;: 3&#125; ```&quot;</span><br>prompt:<span class="hljs-comment">&quot;Provide the best response to a given instruction. Follow the following steps to craft your response: 1. reason about the given instruction 2. provide a high-quality solution 3. offer a concise explanation 4. write tests to verify the correctness your solution ## Example 1 ### Instruction Design a Python function to encode a list of strings into a unique list with the same length, order, and meaning. The new list is formed by appending asterisks (*) to duplicate strings. For instance, given [&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;a&#x27;, &#x27;c&#x27;], the function should return [&#x27;a&#x27;, &#x27;a*&#x27;, &#x27;b&#x27;, &#x27;a**&#x27;, &#x27;c&#x27;], while for [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] it should return [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] without any changes. Make a precondition check through `assert` to ensure the input is a list of strings. Solve the problem in two lines of code, one for the precondition check and the other for the main logic. ### Response [Reasoning] You can achieve this functionality by first ensuring the input meets your requirements using an `assert` statement with list comprehension. Then, use another list comprehension to iterate through the input list and append `&#x27;*&#x27;` to the strings. The number of `&#x27;*&#x27;` is the number of occurrences of the string before the current index. [Implementation] Here&#x27;s how you can do it in two lines of Python code: ```python def encode_strings(input_list): assert all(isinstance(item, str) for item in input_list), &quot;</span><span class="hljs-type">Input</span> must be a list of strings<span class="hljs-comment">&quot; return [s + &#x27;*&#x27; * input_list[:i].count(s) for i, s in enumerate(input_list)] ``` [Explanation] The `enumerate` function provides both the index and the string in each iteration, allowing you to count the occurrences of the string before the current index. [Tests] Now you can test your function with the provided examples: ```python assert encode_strings([&#x27;a&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;a&#x27;, &#x27;c&#x27;]) == [&#x27;a&#x27;, &#x27;a*&#x27;, &#x27;b&#x27;, &#x27;a**&#x27;, &#x27;c&#x27;] assert encode_strings([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]) == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;] ``` Note that although the function is concise, it is not the most efficient solution for large lists, as the `count` method has a time complexity of O(n) for each iteration. For larger lists, a more efficient approach might be to use a dictionary to store the counts of each string and then iterate through the list to append the appropriate number of `&#x27;*&#x27;` to each string. ## Example 2 ### Instruction Write a Python function that takes a dictionary as an argument and makes a copy of it by creating a new dictionary. Modify the copy by deleting a specific key from the dictionary if it exists. ### Response&quot;</span><br>response:<span class="hljs-comment">&quot;To make a copy of a dictionary, you can use the built-in `dict()` function, which creates a new dictionary from an existing dictionary. To delete a specific key from the dictionary, you can use the `del` keyword or the `pop()` method. Here&#x27;s how you can implement this in Python: ```python def copy_and_delete(dictionary, key): copy_dict = dict(dictionary) if key in copy_dict: del copy_dict[key] return copy_dict ``` The above code makes a copy of the dictionary using `dict()` to create a new dictionary from the existing one. Then, if the specified key exists in the copy, it is deleted from the copy using `del`. The function returns the modified copy.&quot;</span><br></code></pre></td></tr></table></figure></p>
<p>Difference: Larger ifd instructions are shorter and more abstract,
and therefore more difficult to learn?</p>
<h3
id="superfiltering-weak-to-strong-data-filtering-for-fast-instruction-tuning">Superfiltering:
Weak-to-Strong Data Filtering for Fast Instruction-Tuning</h3>
<p>One sentence summary: Demonstrate whether it is feasible to filter
fine-tuning data based on small models and then use it for instruction
fine-tuning training of large models</p>
<h5 id="evaluation">Evaluation</h5>
<p>The main reason why this article and the previous work can work is to
ensure the consistency of knowledge before and after instruction
fine-tuning, that is, before instruction fine-tuning, the model is used
to eliminate the world knowledge that is not part of the model itself
(pre-train stage). However, this work did not guarantee that with the
passage of time and the update of later time data, the new LLM would
still have the same command difficulty perception ability as the old
model such as GPT-2, that is, the sequencing differences of IFD screened
sequences became more and more large.</p>
<h5 id="abstract-conclusion">Abstract &amp; Conclusion</h5>
<img src="/2024/10/21/Implementation/4.png" srcset="/img/loading.gif" lazyload class="">
<p>Firstly, the consistency of small model and large model perception of
instruction complexity is proved, and based on this, an instruction
fine-tuning method named "Super filtering" is proposed. Specifically,
the small model is used to evaluate the instruction data, and then the
filtered data is used to fine-tune the larger model.</p>
<p>IFD is still used as an evaluation indicator. Fine-tune the data set
for a given instruction, GPT-2 model and others directly used to
calculate the IFD score of each sample. Then the top k-percent samples
with the highest IFD scores under 1 are selected for faster instruction
tuning.</p>
<h5 id="design-experiment">Design experiment</h5>
<ol type="1">
<li>Dataset: Alpaca Dataset; Models: GPT-2, GPT-2-Large, GPT-2-XL,
GPT-NEO(1.3B), LlaMA3-8B</li>
<li>Calculate ppl and IFD scores of this dataset on different models and
visualize the results</li>
<li>Taking the results of LlaMA3-8b as reference, the ppl and IFD score
ranking obtained by other models were calculated with the similarity
spearman coefficient ##### Reproduce process</li>
<li>Calculate ppl and ifd scores for each model on the dataset
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs script">python code_ifd/data_analysis.py \<br>    --data_path data/alpaca_data.json \<br>    --save_path alpaca_data_gpt2_scores.jsonl \<br>    --model_name_or_path gpt2 <br><br>Same with the rest<br></code></pre></td></tr></table></figure></li>
</ol>
<p>Starting with xl really takes time...</p>
<p>Due to limited video memory, a total of three Windows were opened at
the same time, and the final time took about 2.5h Because LlaMA3.1-8B is
too slow, the final result does not include it</p>
<ol start="2" type="1">
<li>Map score back to the original data <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs script">python code_ifd/put_analysis_to_data.py \<br>    --pt_data_path alpaca_data_gpt2_scores.jsonl \<br>    --json_data_path data/alpaca_data.json \<br>    --json_save_path 1/alpaca_data_gpt2_data.json<br><br>Same with the rest<br></code></pre></td></tr></table></figure></li>
</ol>
<p>This process is fast</p>
<ol start="3" type="1">
<li>Organize the data sequence <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs script">python code_ifd/select_data.py \<br>    --json_data_path 1/alpaca_data_gpt2_data.json \<br>    --json_save_path alpaca_data_gpt2_data_full.json \<br>    --sample_rate 1 \<br>    --filter_threash 2<br><br>Same with the rest<br></code></pre></td></tr></table></figure> Be careful to set threash
to prevent ifd&gt;1 from being all shaved clean</li>
</ol>
<h5 id="ppl">ppl</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>folder_path = <span class="hljs-string">&#x27;data/&#x27;</span>  <br><br>file_names = [<span class="hljs-string">&#x27;alpaca_data_gpt2_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;alpaca_data_gpt2-large_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;alpaca_data_gpt2-xl_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;alpaca_data_gpt-neo_data_full.json&#x27;</span>]<br>file_paths = [os.path.join(folder_path, file_name) <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> file_names]<br><br>model_labels = [<span class="hljs-string">&#x27;gpt2&#x27;</span>, <span class="hljs-string">&#x27;gpt2-large&#x27;</span>, <span class="hljs-string">&#x27;gpt2-xl&#x27;</span>, <span class="hljs-string">&#x27;gpt-neo&#x27;</span>]<br><br>filtered_ifd_ppl_dict = &#123;&#125;<br><br><span class="hljs-keyword">for</span> file_path, model_label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(file_paths, model_labels):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>            alpaca_data = json.load(file)<br>            ifd_ppl_values = [item[<span class="hljs-string">&#x27;ppl_A_condition&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> alpaca_data <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;ppl_A_condition&#x27;</span> <span class="hljs-keyword">in</span> item]<br>            <br>            upper_limit = np.quantile(ifd_ppl_values, <span class="hljs-number">0.9</span>)<br>            lower_limit = np.quantile(ifd_ppl_values, <span class="hljs-number">0.01</span>)<br>            <br>            filtered_values = [value <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> ifd_ppl_values <span class="hljs-keyword">if</span> lower_limit &lt;= value &lt;= upper_limit]<br>            <br>            filtered_ifd_ppl_dict[model_label] = filtered_values<br>    <span class="hljs-keyword">except</span> FileNotFoundError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;File not found: <span class="hljs-subst">&#123;file_path&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">except</span> json.JSONDecodeError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error decoding JSON in file: <span class="hljs-subst">&#123;file_path&#125;</span>&quot;</span>)<br><br>plt.violinplot(dataset=[filtered_ifd_ppl_dict[model] <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> model_labels], showmedians=<span class="hljs-literal">True</span>)<br>plt.xticks(ticks=np.arange(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(model_labels) + <span class="hljs-number">1</span>), labels=model_labels, rotation=<span class="hljs-number">45</span>)<br><br>plt.title(<span class="hljs-string">&#x27;Filtered ppl Comparison&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Model&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;ppl&#x27;</span>)<br><br>output_file = <span class="hljs-string">&#x27;./data/ppl.png&#x27;</span><br>plt.savefig(output_file)<br></code></pre></td></tr></table></figure>
<p>After repeated experiments, it is found that the ppl diagram in the
paper refers to ppl_A_condition, and the upper limit is 0.9 quantile</p>
<img src="/2024/10/21/Implementation/5.png" srcset="/img/loading.gif" lazyload class="">
<h5 id="idf">idf</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>folder_path = <span class="hljs-string">&#x27;data/&#x27;</span> <br><br>file_names = [<span class="hljs-string">&#x27;alpaca_data_gpt2_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;alpaca_data_gpt2-large_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;alpaca_data_gpt2-xl_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;alpaca_data_gpt-neo_data_full.json&#x27;</span>]<br>file_paths = [os.path.join(folder_path, file_name) <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> file_names]<br><br>model_labels = [<span class="hljs-string">&#x27;gpt2&#x27;</span>, <span class="hljs-string">&#x27;gpt2-large&#x27;</span>, <span class="hljs-string">&#x27;gpt2-xl&#x27;</span>, <span class="hljs-string">&#x27;gpt-neo&#x27;</span>]<br><br>filtered_ifd_ppl_dict = &#123;&#125;<br><br><span class="hljs-keyword">for</span> file_path, model_label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(file_paths, model_labels):<br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>            alpaca_data = json.load(file)<br>            ifd_ppl_values = [item[<span class="hljs-string">&#x27;ifd_ppl&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> alpaca_data <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;ifd_ppl&#x27;</span> <span class="hljs-keyword">in</span> item]<br>            <br>            upper_limit = np.quantile(ifd_ppl_values, <span class="hljs-number">0.99</span>)<br>            <br>            filtered_values = [value <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> ifd_ppl_values <span class="hljs-keyword">if</span> <span class="hljs-number">0</span> &lt;= value &lt;= upper_limit]<br>            <br>            filtered_ifd_ppl_dict[model_label] = filtered_values<br>    <span class="hljs-keyword">except</span> FileNotFoundError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;File not found: <span class="hljs-subst">&#123;file_path&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">except</span> json.JSONDecodeError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error decoding JSON in file: <span class="hljs-subst">&#123;file_path&#125;</span>&quot;</span>)<br><br>plt.violinplot(dataset=[filtered_ifd_ppl_dict[model] <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> model_labels], showmedians=<span class="hljs-literal">True</span>)<br>plt.xticks(ticks=np.arange(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(model_labels) + <span class="hljs-number">1</span>), labels=model_labels, rotation=<span class="hljs-number">45</span>)<br><br>plt.title(<span class="hljs-string">&#x27;Filtered ifd_ppl Comparison&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Model&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;ifd_ppl&#x27;</span>)<br><br>output_file = <span class="hljs-string">&#x27;./data/ifd_ppl.png&#x27;</span><br>plt.savefig(output_file)<br></code></pre></td></tr></table></figure>
<p>The upper limit of 0.99 quantile is closer to the experimental
results of the paper</p>
<img src="/2024/10/21/Implementation/6.png" srcset="/img/loading.gif" lazyload class="">
<h5 id="spearman">Spearman</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> spearmanr<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/alpaca_data_gpt-neo_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data1 = json.load(f)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;data/alpaca_data_gpt2-xl_data_full.json&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data2 = json.load(f)<br><br>ids1 = [item[<span class="hljs-string">&#x27;output&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data1]<br>ids2 = [item[<span class="hljs-string">&#x27;output&#x27;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> data2]<br><br>common_ids = <span class="hljs-built_in">set</span>(ids1) &amp; <span class="hljs-built_in">set</span>(ids2)<br><br>ranks1 = [ids1.index(id_) + <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> id_ <span class="hljs-keyword">in</span> common_ids]  <br>ranks2 = [ids2.index(id_) + <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> id_ <span class="hljs-keyword">in</span> common_ids]<br><br>spearman_corr, p_value = spearmanr(ranks1, ranks2)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Spearman Rank Correlation: <span class="hljs-subst">&#123;spearman_corr&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;P-value: <span class="hljs-subst">&#123;p_value&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>neo:1 gpt2: 0.823 gpt2-large: 0.872 gpt-xl: 0.870</p>
<h3
id="less-selecting-influential-data-for-targeted-instruction-tuning">LESS:
Selecting Influential Data for Targeted Instruction Tuning</h3>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/PROJECT/" class="category-chain-item">PROJECT</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/PAPER/" class="print-no-link">#PAPER</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Implementation</div>
      <div>http://example.com/2024/10/21/Implementation/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Zhili Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>October 21, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/10/21/Project/" title="Project">
                        <span class="hidden-mobile">Project</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"7mJuq3fkcSAuEaGNgs89rWXu-gzGzoHsz","appKey":"WZ89ph5dYWgalvSmCqwuyaqg","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        Views: 
        <span id="leancloud-site-pv"></span>
        
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        Visitors: 
        <span id="leancloud-site-uv"></span>
        
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
